{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ebed44-a2d2-4965-9048-7d4caece6d82",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. 准备环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9bdcf5-f21e-40f2-8979-548cb1db6ba5",
   "metadata": {},
   "source": [
    "### 1.1 安装依赖"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f66b4b-15f8-47fa-a6c0-70795799ad31",
   "metadata": {},
   "source": [
    "现在，让我们安装一些额外的库，例如 langchain 和 python-dotenv。\n",
    "\n",
    "前者为我们提供了一个构建基于LLM的应用程序的模块化框架，而后者在为在线LLM服务设置API密钥方面为我们节省了时间（有关详细信息，请参见下一节）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0608b18-2faf-40f8-beaf-efbd713e4f63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:40:47.645907900Z",
     "start_time": "2023-11-26T11:40:28.475675600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting langchain==0.0.338\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ce/3f/1dafc52526337d1c554227b0e6f16a1aee18e63bf5cd03fd7774297059b2/langchain-0.0.338-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain==0.0.338) (6.0)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8d/e2/528c52001a743a7faa28e6d3095d9f01b472d3efee62d62101403bf1a70a/dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain==0.0.338) (1.4.39)\n",
      "Collecting pydantic<3,>=1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/0a/2b/64066de1c4cf3d4ed623beeb3bbf3f8d0cc26661f1e7d180ec5eb66b75a5/pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5e/c4/3be0c9e158cf9627f5cd60c5149825aa98a402926b61eaf9111bdbc102b5/aiohttp-3.9.0-cp39-cp39-win_amd64.whl (365 kB)\n",
      "     -------------------------------------- 365.0/365.0 kB 5.7 MB/s eta 0:00:00\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain==0.0.338) (2.28.1)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain==0.0.338) (3.5.0)\n",
      "Collecting langsmith<0.1.0,>=0.0.63\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/84/9e/208314830d8c523dae4dec41ab5aeeb2d42dc1667bbc3ff8b875244b3012/langsmith-0.0.66-py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.8/46.8 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain==0.0.338) (1.21.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.338) (21.4.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f9/16/ef36f5b20ee10dba86d4b5223d55b416e97dfa2dbf5546f0c6d9aa8a26ba/frozenlist-1.4.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "     ---------------------------------------- 44.7/44.7 kB ? eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8b/d3/44103fb90e5b9d53cf141bc080f4141c7594f4238be3569581258bd6fff3/yarl-1.9.3-cp39-cp39-win_amd64.whl (76 kB)\n",
      "     ---------------------------------------- 76.2/76.2 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f1/d2/d735d40355ce41f6d1c50a5d4feef47cd4aad0e2809dd2c8cb01601f04ac/multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<4.0->langchain==0.0.338) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<4.0->langchain==0.0.338) (1.2.0)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.4/49.4 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.338) (2.1)\n",
      "Collecting pydantic-core==2.14.5\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/41/64/43de643a6d2d157a8ac508a7c2a6a9746c941a659a6c64e00ebd13d5db4f/pydantic_core-2.14.5-cp39-none-win_amd64.whl (1.9 MB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.338) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.338) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.338) (2.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.338) (1.1.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.338) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.338) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.338) (3.0.9)\n",
      "Installing collected packages: typing-extensions, tenacity, multidict, jsonpatch, frozenlist, async-timeout, annotated-types, yarl, typing-inspect, pydantic-core, marshmallow, aiosignal, pydantic, dataclasses-json, aiohttp, langsmith, langchain\n",
      "Successfully installed aiohttp-3.9.0 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 dataclasses-json-0.6.2 frozenlist-1.4.0 jsonpatch-1.33 langchain-0.0.338 langsmith-0.0.66 marshmallow-3.20.1 multidict-6.0.4 pydantic-2.5.2 pydantic-core-2.14.5 tenacity-8.2.3 typing-extensions-4.8.0 typing-inspect-0.9.0 yarl-1.9.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script langsmith.exe is installed in 'C:\\Users\\86186\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script langchain-server.exe is installed in 'C:\\Users\\86186\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# Install langchain, the library we will learn during our courses\n",
    "!pip install langchain==0.0.338 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892e98f2-bbf1-4c8f-a755-5a8c64e9a405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:40:52.467932100Z",
     "start_time": "2023-11-26T11:40:47.627138100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting python-dotenv==1.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/44/2f/62ea1c8b593f4e093cc1a7768f0d46112107e790c3e478532329e434f00b/python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script dotenv.exe is installed in 'C:\\Users\\86186\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# Install dotenv, auto-load environment variables from `.env` files\n",
    "!pip install python-dotenv==1.0.0 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2919c726-32d3-4025-9e8f-db00e5ca1c74",
   "metadata": {},
   "source": [
    "此外，让我们安装用于对内容进行标记化和存储在向量数据库上的库，即 tiktoken 和 faiss-cpu。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c3e332c-0324-42ca-b5ca-8be73cfea0d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:40:58.107262200Z",
     "start_time": "2023-11-26T11:40:52.448928300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting tiktoken==0.5.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/91/cf/7f3b821152f7abb240950133c60c394f7421a5791b020cedb190ff7a61b4/tiktoken-0.5.1-cp39-cp39-win_amd64.whl (760 kB)\n",
      "     -------------------------------------- 760.0/760.0 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken==0.5.1) (2.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken==0.5.1) (2022.7.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.5.1) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.5.1) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.5.1) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.5.1) (2022.9.14)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.5.1\n"
     ]
    }
   ],
   "source": [
    "# Install tiktoken, the library used by OpenAI models for tokenizing text strings\n",
    "!pip install tiktoken==0.5.1 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55858b86-2ff1-46a7-a473-78295437ecd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:41:03.624906200Z",
     "start_time": "2023-11-26T11:40:58.098805100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting faiss-cpu==1.7.4\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d9/b6/97164ce265a66ffc90810cc4c9a241934bba8de2cff46645b0df3faf5c3d/faiss_cpu-1.7.4-cp39-cp39-win_amd64.whl (10.8 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.4\n"
     ]
    }
   ],
   "source": [
    "# Install faiss-cpu, a vector database for storing content along with embedding vectors\n",
    "!pip install faiss-cpu==1.7.4 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2865033a-0683-4b6a-a478-8f6b9d120765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:41:08.752926300Z",
     "start_time": "2023-11-26T11:41:03.609014500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting wikipedia==1.4.0\n",
      "  Using cached wikipedia-1.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from wikipedia==1.4.0) (4.11.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wikipedia==1.4.0) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (3.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia==1.4.0) (2.3.1)\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "# Install wikipedia, the library for accessing wikipedia service in code\n",
    "!pip install wikipedia==1.4.0 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5f5f4-63d3-441d-8c9a-f7976f33555c",
   "metadata": {},
   "source": [
    "然后，安装一些用于访问外部服务的库，例如 wikipedia。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a14613b-82a4-40b2-8c82-770d5cb7b63e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:41:12.689745600Z",
     "start_time": "2023-11-26T11:41:08.755950700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: wikipedia==1.4.0 in c:\\users\\86186\\appdata\\roaming\\python\\python39\\site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wikipedia==1.4.0) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from wikipedia==1.4.0) (4.11.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (2.0.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia==1.4.0) (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "# Install wikipedia, the library for accessing wikipedia service in code\n",
    "!pip install wikipedia==1.4.0 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3711d50-d9ac-44b3-b7c6-25b084474119",
   "metadata": {},
   "source": [
    "最后，为了测试安装和API密钥的有效性，我们还安装相应供应商的SDK库（即OpenAI和智谱AI）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2623724c-492a-4737-be44-0ae014214042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:41:21.489692800Z",
     "start_time": "2023-11-26T11:41:12.675402400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting openai==1.3.3\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/69/95/22a9a81cebd54e18841da429f05f06ed867648768f7af938ad34f13197fd/openai-1.3.3-py3-none-any.whl (220 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\86186\\appdata\\roaming\\python\\python39\\site-packages (from openai==1.3.3) (4.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\86186\\appdata\\roaming\\python\\python39\\site-packages (from openai==1.3.3) (2.5.2)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f4/2c/c90a3adaf0ddb70afe193f5ebfb539612af57cffe677c3126be533df3098/distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai==1.3.3) (3.5.0)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a2/65/6940eeb21dcb2953778a6895281c179efd9100463ff08cb6232bb6480da7/httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai==1.3.3) (4.64.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<4,>=3.5.0->openai==1.3.3) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<4,>=3.5.0->openai==1.3.3) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.3.3) (2022.9.14)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\86186\\appdata\\roaming\\python\\python39\\site-packages (from pydantic<3,>=1.9.0->openai==1.3.3) (2.14.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\86186\\appdata\\roaming\\python\\python39\\site-packages (from pydantic<3,>=1.9.0->openai==1.3.3) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai==1.3.3) (0.4.5)\n",
      "Installing collected packages: h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script distro.exe is installed in 'C:\\Users\\86186\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'C:\\Users\\86186\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'C:\\Users\\86186\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# Install openai, official SDK by OpenAI for invoking GPT models\n",
    "!pip install openai==1.3.3 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1338b17d-d953-4742-9fed-e8a2080170b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:41:43.946545300Z",
     "start_time": "2023-11-26T11:41:38.522044100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: zhipuai==1.0.7 in c:\\users\\86186\\appdata\\roaming\\python\\python39\\site-packages (1.0.7)\n",
      "Requirement already satisfied: cachetools in c:\\users\\86186\\appdata\\roaming\\python\\python39\\site-packages (from zhipuai==1.0.7) (5.3.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from zhipuai==1.0.7) (2.28.1)\n",
      "Requirement already satisfied: PyJWT in c:\\programdata\\anaconda3\\lib\\site-packages (from zhipuai==1.0.7) (2.4.0)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\86186\\appdata\\roaming\\python\\python39\\site-packages (from zhipuai==1.0.7) (0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->zhipuai==1.0.7) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->zhipuai==1.0.7) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->zhipuai==1.0.7) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->zhipuai==1.0.7) (2022.9.14)\n"
     ]
    }
   ],
   "source": [
    "# Install zhipu, official SDK by OpenAI for invoking ChatGLM models\n",
    "!pip install zhipuai==1.0.7 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06972013-340f-427f-9038-12cde927c9a7",
   "metadata": {},
   "source": [
    "### 1.2 环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6cfdeb-fdbf-4a09-a8fa-0ed98e470606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:41:27.539821600Z",
     "start_time": "2023-11-26T11:41:27.475800800Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ZHIPUAI_API_KEY']='7f41de0c4405d3c30457c9cd0b74609b.AMbOH4LogZyMo7IV'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5017855e-c925-4264-9319-e47ebcbe250b",
   "metadata": {},
   "source": [
    "### 1.3 测试准备是否成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af19cdeb-20c5-44aa-85b2-6df9422bf5ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:43:50.151896200Z",
     "start_time": "2023-11-26T11:43:50.089243800Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'zhipuai'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_21320\\1538175095.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Test zhipuai installation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mzhipuai\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mzhipuai\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapi_key\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetenv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'ZHIPUAI_API_KEY'\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Set API key from envrionment variable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'zhipuai'"
     ]
    }
   ],
   "source": [
    "# Test zhipuai installation\n",
    "import os\n",
    "import zhipuai\n",
    "\n",
    "zhipuai.api_key = os.getenv('ZHIPUAI_API_KEY')  # Set API key from envrionment variable\n",
    "\n",
    "prompt = \"\"\"You will be provided with a sentence in English, and your task is to translate it into Chinese.\n",
    "\n",
    "My name is Jane. What is yours?\n",
    "\"\"\"\n",
    "\n",
    "completion = zhipuai.model_api.invoke(\n",
    "    model='chatglm_turbo',\n",
    "    prompt=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ],\n",
    "    temperature=0.,\n",
    ")\n",
    "\n",
    "print(completion['data']['choices'][0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0678d-8625-41ce-b335-cb09274c868d",
   "metadata": {},
   "source": [
    "## 2. Langchain基础练习（基于智谱LLM）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b07742-bfc3-4e59-888f-f5619a9fe247",
   "metadata": {},
   "source": [
    "与OpenAI不同，LangChain并不原生支持智谱AI的在线LLM服务。相反，我们可以编写一个包装类来将智谱AI的ChatGLP服务移植到LangChain，这要归功于LangChain的模块化接口。这应该类似于我们使用OpenAI的GPT服务时的感觉。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c752ae-14ff-451b-a30d-cb1190340da2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:44:20.727379200Z",
     "start_time": "2023-11-26T11:44:20.633534600Z"
    }
   },
   "source": [
    "### 2.1 检查ZhipuAI wrapper是否存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4c40040-163c-4df3-a869-15a4fa931043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:38:37.414992600Z",
     "start_time": "2023-11-26T11:38:37.335940400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "# Check ZhipuAI wrapper existence\n",
    "!ls -la | grep \"zhipuai\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8e2d6-86c1-4900-8398-fa25a3559aea",
   "metadata": {},
   "source": [
    "### 2.2 简单使用例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18bd3d2f-b446-42a6-9920-7ad218dfc003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:38:48.168855700Z",
     "start_time": "2023-11-26T11:38:47.281905400Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'zhipuai_llm'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mzhipuai_llm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ZhipuAILLM\n\u001B[0;32m      3\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mYou will be provided with a sentence in English, and your task is to translate it into Chinese.\u001B[39m\n\u001B[0;32m      4\u001B[0m \n\u001B[0;32m      5\u001B[0m \u001B[38;5;124mMy name is Jane. What is yours?\u001B[39m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m      8\u001B[0m llm \u001B[38;5;241m=\u001B[39m ZhipuAILLM(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchatglm_turbo\u001B[39m\u001B[38;5;124m'\u001B[39m, temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'zhipuai_llm'"
     ]
    }
   ],
   "source": [
    "from zhipuai_llm import ZhipuAILLM\n",
    "\n",
    "prompt = \"\"\"You will be provided with a sentence in English, and your task is to translate it into Chinese.\n",
    "\n",
    "My name is Jane. What is yours?\n",
    "\"\"\"\n",
    "\n",
    "llm = ZhipuAILLM(model='chatglm_turbo', temperature=0.)\n",
    "\n",
    "response = llm.predict(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb88ab0-0ba3-4140-a939-ae91f39b4521",
   "metadata": {},
   "source": [
    "#### 练习1 - \"计算时间复杂度\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc11a5-6e42-4419-b3f6-ad8d0f2fa105",
   "metadata": {},
   "source": [
    "> 💪 Practice yourself.\n",
    "> Please finish the code for this task, with the following prompt example:\n",
    ">\n",
    "> ---------------------------\n",
    "> \n",
    "> ```\n",
    "> You will be provided with Python code, and your task is to calculate its time complexity.\n",
    ">\n",
    "> def foo(n, k):\n",
    ">    accum = 0\n",
    ">    for i in range(n):\n",
    ">        for l in range(k):\n",
    ">            accum += i\n",
    ">    return accum\n",
    "> ```\n",
    "> \n",
    "> ---------------------------\n",
    "> Try to change the Python code for analysis and see how LLM responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d167350b-bca4-4bd0-9a15-0f10e8d6187d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e19a3a-dd46-464b-8612-c103dd0e3427",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### 练习2 - “微博情感分析”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641d45ed-cc60-4d04-a4c6-6719721e4889",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "> 💪 Practice yourself.\n",
    "> Please finish the code for this task, with the following prompt example:\n",
    ">\n",
    "> ---------------------------\n",
    "> ```\n",
    "> You will be provided with a tweet, and your task is to classify its sentiment as \n",
    "> positive, neutral, or negative.\n",
    "> \n",
    "> I loved the new Batman movie!\n",
    "> ```\n",
    ">\n",
    "> ---------------------------\n",
    "> Try to change the tweet text for analysis and see how LLM responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e4b7ba-2bb0-46cc-9407-7855b101710c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f1a19-cabc-4801-9178-9024748a8a8d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### 练习3 - “机场代号提取”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf980e2b-c9c0-4cdf-8b44-062027f8fa8c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "> 💪 Practice yourself.\n",
    "> Please finish the code for this task, with the following prompt example:\n",
    ">\n",
    "> ---------------------------\n",
    "> ```\n",
    "> You will be provided with a text, and your task is to extract the airport codes from it.\n",
    "> \n",
    "> I want to fly from Orlando to Boston\n",
    "> ```\n",
    ">\n",
    "> ---------------------------\n",
    "> Try to change the city names and see how LLM responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10b019-a071-407a-8e4e-0fb13cdbc2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09091de-7a0a-4338-918c-cca0608a2397",
   "metadata": {},
   "source": [
    "### 2.3 探索LLM局限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e6a1b5-e44e-47ff-9584-8d3040106eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai_llm import ZhipuAILLM\n",
    "\n",
    "prompt = \"\"\"Which team won the 1986 FIFA World Cup?\"\"\"\n",
    "llm = ZhipuAILLM(model='chatglm_turbo', temperature=0.)\n",
    "response = llm.predict(prompt)\n",
    "print(f'- 1st response: {response}')\n",
    "\n",
    "prompt = \"\"\"Which team won the 2022 FIFA World Cup?\"\"\"\n",
    "llm = ZhipuAILLM(model='chatglm_turbo', temperature=0.)\n",
    "response = llm.predict(prompt)\n",
    "print(f'- 2nd response: {response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d69741-cf70-453b-abb8-b865aee1e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai_llm import ZhipuAILLM\n",
    "\n",
    "prompt = \"\"\"Sum 4829 and 2930, and then multiply by 1923.\"\"\"\n",
    "\n",
    "llm = ZhipuAILLM(model='chatglm_turbo', temperature=0.)\n",
    "response = llm.predict(prompt)\n",
    "\n",
    "print(f'- gpt: {response}')\n",
    "print(f'- truth:\\n\\n {(4829 + 2930) * 1923}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d15a3b-39e5-4420-b81e-75a4aed444e0",
   "metadata": {},
   "source": [
    "### 2.4 探索Langchain模块化组件设计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72490709-13f7-4fd1-9fa6-6fed0c61e876",
   "metadata": {},
   "source": [
    "📌 打开调试和详细模式\n",
    "\n",
    "如果您是初学者，我们建议您在LangChain中打开调试和详细模式，在LLM应用程序执行过程中显示中间步骤的额外信息。\n",
    "查看提示如何填充以及中间LLM生成的响应是个好主意（在正常模式下不应打印任何输出）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857b586-03a6-4700-a1a5-83b3e034a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.debug = True\n",
    "langchain.verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ee3a0-2cf6-4dd8-9a4e-f1dfb70227db",
   "metadata": {},
   "source": [
    "#### Model I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa2ad97-46ce-424a-afb7-a94b7ef674ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "from zhipuai_llm import ZhipuAILLM\n",
    "\n",
    "# [1] Custom output parser, split comma separated strings and return as list\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "# [2] System message template, declare task requirement as prompt\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "\n",
    "# [3] Human message template, here we use Python format string syntax\n",
    "# (https://docs.python.org/3/library/string.html#formatstrings)\n",
    "human_template = '{text}'\n",
    "\n",
    "# [4] We send both messages to LLM for response\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', template),\n",
    "    ('human', human_template),\n",
    "])\n",
    "\n",
    "# [5] Build up simple chain with LangChain Expression Language\n",
    "# (https://python.langchain.com/docs/expression_language/)\n",
    "chain = chat_prompt | ZhipuAILLM(model='chatglm_turbo') | CommaSeparatedListOutputParser()\n",
    "\n",
    "# [6] Call simple chain with human input, i.e., text = \"colors\"\n",
    "chain.invoke({'text': 'colors'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd5c10-9981-474c-9ad2-288ede059f10",
   "metadata": {},
   "source": [
    "#### Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf40377-0d36-4250-9585-41dc0a63ea56",
   "metadata": {},
   "source": [
    "在接下来的部分，我们将专注于传统的Chain接口。首先开始重写前一节中的ICEL风格链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652675c6-df3b-426e-b6b6-97efc878af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "from zhipuai_llm import ZhipuAILLM\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "\n",
    "human_template = '{text}'\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', template),\n",
    "    ('human', human_template),\n",
    "])\n",
    "\n",
    "# Equivalent to `chain = chat_prompt | ZhipuAILLM(model='chatglm_turbo') | CommaSeparatedListOutputParser()`\n",
    "chain = LLMChain(\n",
    "    llm=ZhipuAILLM(model='chatglm_turbo'),\n",
    "    prompt=chat_prompt,\n",
    "    output_parser=CommaSeparatedListOutputParser(),\n",
    ")\n",
    "\n",
    "chain.invoke({'text': 'colors'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d039d6c-ad90-4b0b-bbba-1a71588878d6",
   "metadata": {},
   "source": [
    "然后，让我们看一个更复杂的链。我们将介绍一个简单的两阶段连续链，其中：\n",
    "\n",
    "1. 为一家制造某种产品的公司提出名称\n",
    "2. 为提出的公司写一个简短的描述（即口号）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8bcd6b-f5e7-44f0-90bd-192e352c91a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "from zhipuai_llm import ZhipuAILLM\n",
    "\n",
    "product = 'Pure Milk'\n",
    "\n",
    "# [0] The same LLM instance shared by both chains (remember LLM is stateless)\n",
    "llm = ZhipuAILLM(model='chatglm_turbo', temperature=0.7)\n",
    "\n",
    "# [1] Build name chain (1st chain)\n",
    "name_template = \"\"\"What is the best name to describe a company that makes {product}?\"\"\"\n",
    "name_prompt = ChatPromptTemplate.from_template(name_template)\n",
    "name_chain = LLMChain(llm=llm, prompt=name_prompt)\n",
    "\n",
    "# [2] Build slogan chain (2nd chain)\n",
    "slogan_template = \"\"\"Write a 20 words slogan for the following company:{company_name}\"\"\"\n",
    "slogan_prompt = ChatPromptTemplate.from_template(slogan_template)\n",
    "slogan_chain = LLMChain(llm=llm, prompt=slogan_prompt)\n",
    "\n",
    "# [3] Construct final chain in a sequencial manner\n",
    "overall_chain = SimpleSequentialChain(chains=[name_chain, slogan_chain])\n",
    "\n",
    "# [4] Call our final chain to propose and write slogan\n",
    "overall_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cee8a2-5574-4f87-9d45-8f2161edd5b6",
   "metadata": {},
   "source": [
    "#### Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316dca0f-aef3-4a36-8edc-d68d55c40893",
   "metadata": {},
   "source": [
    "回顾一下我们说过的LLM本质上是无状态的，即后续调用永远不会回忆起在之前的调用中提到的信息。让我们看一个例子来说明这个说法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06801d81-a3f2-46e1-a7db-1a33bba1b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai_llm import ZhipuAILLM\n",
    "\n",
    "llm = ZhipuAILLM(model='chatglm_turbo', temperature=0.7)\n",
    "print(f'Initial message: {llm.predict(\"Hello, my name is Charles.\")}')\n",
    "print(f'Follow-up message: {llm.predict(\"Well, what is my name?\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780d238-cf65-4356-bbc6-797acef6fed1",
   "metadata": {},
   "source": [
    "现在，让我们看看如何在LangChain中为一个对话应用程序添加一个记忆模块。具体来说，我们将使用ConversationBufferMemory记忆模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1731ea5-edd8-42c3-9a3b-a4d1ccc02913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from zhipuai_llm import ZhipuAILLM\n",
    "\n",
    "# [1] Notice that \"chat_history\" is present in the prompt template\n",
    "template = \"\"\"You are a nice chatbot having a conversation with a human.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "New human question: {question}\n",
    "Response:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# [2] Notice that we need to align the `memory_key`\n",
    "memory = ConversationBufferMemory(memory_key='chat_history')\n",
    "\n",
    "llm = ZhipuAILLM(model='chatglm_turbo', temperature=0.7)\n",
    "\n",
    "# [3] Memory should work with Chain for effect\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "print(f'Initial message: {chain.invoke(\"Hello, my name is Charles.\")[\"text\"]}')\n",
    "print(f'Follow-up message: {chain.invoke(\"Well, what is my name?\")[\"text\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b293b-93c1-4c4c-9b41-e0ecda1d0c31",
   "metadata": {},
   "source": [
    "#### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe394b53-6399-4e64-9a51-a9544a62590e",
   "metadata": {},
   "source": [
    "现在，让我们看一个简单的检索方式，即基于向量存储的检索器，并看看它在LangChain组件中的工作原理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496c96be-ce08-4cb3-8b2c-6cc0d5b060a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "\n",
    "# [1] Load content from disk file\n",
    "loader = TextLoader('流浪地球.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# [2] Transform file content into splits for storage and retrieve\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# [3] Here we invoke embedding functions provided by OpenAI services, which maps text\n",
    "#     string of any size into a fixed size embedding vector, where similar text are\n",
    "#     mapped into vectors of short distance\n",
    "# [4] We use FAISS as our vector store backend to save content along with embedding vectors\n",
    "embeddings = ZhipuAIEmbeddings()\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# [5] Retriever can be directly accessed from vector store instance\n",
    "retriever = db.as_retriever()\n",
    "docs = retriever.get_relevant_documents(\"流浪地球计划\")\n",
    "\n",
    "# [6] Interate around retrieved documents and print first 100 characters of each\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f'doc #{i}: {doc.page_content[:100]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c0779-3941-46ac-955e-944f708a23bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 2.5 LangChain: Hands-On 练习4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2780749e-1242-4815-92ce-ec87d6617ed9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "在本节中，我们将借助LangChain框架构建一个简单的LLM应用程序。我们即将构建的应用程序是一个文档聊天机器人，允许您就文档文件的内容提出问题。有关更多信息，请参阅[Chatbot](https://python.langchain.com/docs/use_cases/chatbots)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a0149-d6a9-4ce2-bec8-17c549ba5bd4",
   "metadata": {},
   "source": [
    "**step1:**\n",
    "\n",
    "让我们首先定义要使用的LLM模型。与以前一样，可以使用智谱AI。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8eb571-9c5c-4df0-a945-0485da2806e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ab12d-7617-48ed-95fa-99058b316f5e",
   "metadata": {},
   "source": [
    "**step2:**\n",
    "  \n",
    "然后，创建一个用于存储历史聊天消息的记忆，这使得聊天机器人能够记住先前的对话。在这里，不再使用之前的ConversationBufferMemory，而是尝试另一种记忆，即ConversationSummaryMemory。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db120e36-3347-4cf8-9eeb-7123b0e69f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0727dc7-45d1-41ab-b008-b2f2a3174ff9",
   "metadata": {},
   "source": [
    "注意，ConversationSummaryMemory接受一个名为llm的参数。\n",
    "\n",
    "实际上，这个记忆保留了两种类型的历史对话信息，即历史消息的列表和历史消息的简短摘要。\n",
    "\n",
    "与ConversationBufferMemory相比，摘要的使用使我们不会使LLM上下文窗口（令牌限制）变得臃肿。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e4d11-4386-4cb2-8460-ed7af7d0f60c",
   "metadata": {},
   "source": [
    "**step3:**\n",
    "\n",
    "之后，让我们完成检索器部分，即加载文档、拆分文本、转换为嵌入并存储在数据库中。\n",
    "  \n",
    "与之前一样，我们将使用FAISS向量存储。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce06be-b6ea-477c-90f3-825d577168eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load数据资源\n",
    "# Write your code here\n",
    "blog_url = 'https://lilianweng.github.io/posts/2023-06-23-agent/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa9dbe-8cb9-4bbe-a4e5-d1b542e891ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分数据成块\n",
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b684fe-7e26-431c-81a5-4ca01b7eec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向量处理存入向量数据库\n",
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e21d4-6c61-4e48-a65b-e9647b662255",
   "metadata": {},
   "source": [
    "**step4:**\n",
    "最后，让我们将上述组件组合成一个单一的链。我们使用的链是`ConversationalRetrievalChain`。该链的工作方式如下：\n",
    "\n",
    "1. 使用聊天历史和新问题创建一个“独立问题”。\n",
    "2. 将这个新问题传递给检索器，并返回相关文档。\n",
    "3. 将检索到的文档与新问题（默认行为）或原始问题和聊天历史一起传递给LLM，生成最终的响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33837b92-bc2f-4a5e-aa56-7dbb6445af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e45e2-ab5c-4677-b75f-d9f796b50081",
   "metadata": {},
   "source": [
    "**step5:**\n",
    "  \n",
    "现在，让我们测试一下我们的聊天机器人。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295bb80e-f4c8-4ffe-ac01-4e2b97371748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question One: 'How do agents use Task decomposition?'\n",
    "# Write your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de5ec0-54bb-44cc-8f32-b0d8e4f57844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Two: 'What are the various ways to implement memory to support it?'\n",
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a79a5a-670c-425b-b287-a0bd77f12acc",
   "metadata": {},
   "source": [
    "## 3. 基于LLM的Agent（基于OpenAI）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfe2e3-6903-46b8-ab75-99443ce79605",
   "metadata": {},
   "source": [
    "**Agent: Hands-On**\n",
    " \n",
    "Agents的核心思想是使用语言模型选择一系列要执行的动作。\n",
    "\n",
    "而在Chains中，一系列动作是硬编码的（在代码中）\n",
    "\n",
    "在Agent中，语言模型被用作推理引擎，确定要执行哪些动作以及顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c49329a-2433-49c0-8951-a2f8ae61443a",
   "metadata": {},
   "source": [
    "为了支持构建基于LLM的Agent），LangChain提供了以下模块化组件，即\n",
    "\n",
    "* `Tool`：包装了一个Python函数和相应的文本描述，它赋予Agent调用外部工具的能力，例如计算器、Python解释器、搜索引擎API。\n",
    "* `Agent`：扩展了普通的LangChain`Chain`模块，具有一组`Tool`，以及用于中间步骤的提示（例如ReAct代理的“思考/动作/观察”追踪），代理执行的输出要么是要采取的下一个动作（`AgentAction`），要么是发送给用户的最终响应（`AgentFinish`）。\n",
    "* `AgentExecutor`：是Agent的运行时，它实际上调用`Agent`，执行它选择的动作，将动作的输出传递回Agent，然后重复，直到达到`AgentFinish`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c2490-2e78-45ac-afaa-52fe2f4f7947",
   "metadata": {},
   "source": [
    "> ❗ 准备您的API密钥\n",
    ">\n",
    "> 确保您已经按照先决条件设置了开发环境，并拥有调用LLM服务的有效API密钥，这里以OpenAI为例。\n",
    ">\n",
    "> 请确保您已经从环境变量中加载了OpenAPI密钥以供使用，如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e0e5e-937d-4b6b-9236-556f2b54bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']='replace_with_your_open_api_key_here'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d56076b-6b0f-460a-a7af-39a34ca3154c",
   "metadata": {},
   "source": [
    "### 3.1 Tool: Python Function + Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cc7f6d-5f81-4074-a75b-8d3a6979f80f",
   "metadata": {},
   "source": [
    "首先，让我们看一下LangChain现成提供的一些内置Tool。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65cc613-fb87-45e4-90ac-ea16e93d8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numexpr -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63423193-4fee-44bc-9ee8-abacea1e954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# [1] Some tools rely on LLM during its execution\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.7)\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents.load_tools import get_all_tool_names\n",
    "\n",
    "math_tools = load_tools(['llm-math'], llm=llm)  # [1] Tool for arithmetic calculation\n",
    "meteo_tools = load_tools(['open-meteo-api'], llm=llm)  # [2] Tool for weather info\n",
    "wiki_tools = load_tools(['wikipedia'])  # [3] Tool for searching on Wikipedia\n",
    "\n",
    "# [4] Print total list of builtin tool names\n",
    "print(get_all_tool_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69c6b5-b8bb-4217-ab30-7133da36993d",
   "metadata": {},
   "source": [
    "#### `llm_math`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018ad41-7e01-4002-8c0f-3b8df5a84405",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math = math_tools[0]\n",
    "\n",
    "# [1] Try a simple equation.\n",
    "print(f'LLM Math: 2 + 2 => {llm_math.run(\"What is 2 + 2?\")}')\n",
    "\n",
    "# [2] How about a slightly diffucult one? Recall that pure LLM may fail on this example.\n",
    "print(f'LLM Math: (4829 + 2930) * 1923 => {llm_math.run(\"Sum 4829 and 2930, and then multiply by 1923.\")}')\n",
    "\n",
    "# [3] Pure LLM failed to reach the correct answer.\n",
    "print(f'Pure LLM: \\n{llm.predict(\"Sum 4829 and 2930, and then multiply by 1923.\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ec366-cb1a-4fa4-9547-54d17a3761c8",
   "metadata": {},
   "source": [
    "#### `open-meteo-api`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c7563-6a31-4333-a5b2-9312ab4ef08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo = meteo_tools[0]\n",
    "print(meteo.run(\"What's the weather in Paris?\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c0e8e80-b1f6-4227-b5f2-3215f980ed18",
   "metadata": {},
   "source": [
    "然后，除了使用LangChain提供的内置Tool，我们还可以定义自己的工具，以便使用简单的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbfecfa-6da0-47b1-9f92-7e04a830b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date\n",
    "\n",
    "@tool  # [1] We use the `tool` decorator to create new `Tool` instance\n",
    "def time(text: str) -> str:\n",
    "    # [2] The docstring (wrapped in \"\"\" \"\"\") are used as tool description\n",
    "    #     (which is sent to LLM when used by agent)\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())  # [3] The actual logic for this `Tool`, i.e, return today's date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412d745-de60-4321-86f4-a59a4e7fa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.run('')  # Note the input is not used in our customed `Tool`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0504426-27d8-4c3d-a143-cb6a419ae12c",
   "metadata": {},
   "source": [
    "另一个自定义工具，它接受多个参数作为输入并返回一个单一的字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde986d1-1517-41fc-b214-f5f60baf8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.tools import tool\n",
    "import requests\n",
    "\n",
    "@tool\n",
    "def post_message(url: str, body: dict, parameters: Optional[dict] = None) -> str:\n",
    "    \"\"\"Sends a POST request to the given url with the given body and parameters.\"\"\"\n",
    "    result = requests.post(url, json=body, params=parameters)\n",
    "    return f\"Status: {result.status_code} - {result.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e9415-cd30-437b-b302-3fa458751a7d",
   "metadata": {},
   "source": [
    "### 3.2  Agent: Chain Equipped with Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f20e32a-9e08-4709-af24-ab0f22b97c17",
   "metadata": {},
   "source": [
    "LangChain已经定义了一些内置的Agent类型，我们可以直接在其基础上构建我们的应用程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe993ae0-9c7e-4be1-b853-24f2cc79c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.types import AgentType\n",
    "print([item.name for item in AgentType])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c7ce7e-c657-40f8-80a8-71aae8a9fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "让我们看一个例子，即ZERO_SHOT_REACT_DESCRIPTION，它类似于零-shot ReAct风格的Agent。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4fb12-d468-4ea1-8b4b-65e2f1ada7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents.mrkl.base import ZeroShotAgent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.7)\n",
    "tools = load_tools(['llm-math', 'open-meteo-api'], llm=llm)\n",
    "\n",
    "agent = ZeroShotAgent.from_llm_and_tools(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5224d308-7681-475c-9c5e-f983ff6f1920",
   "metadata": {},
   "source": [
    "请注意，LangChain中的`Agent`本身不运行，相反，它定义了适当的LLM、工具和提示，在`AgentExecutor`中执行时使用。让我们看看`ZeroShotAgent`是如何构建其提示的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d9616-15d7-4739-82e4-a8df23af4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28bea3d-908f-45f7-8885-1934563f28ae",
   "metadata": {},
   "source": [
    "注意，`{input}` 定义了用户输入或问题的位置，例如，“哪支球队赢得了2022年的FIFA世界杯？”；`{agent_scratchpad}` 是代理呈现其进一步执行的中间步骤的位置，例如，ReAct代理的“思考/动作/观察”三元组序列。按设计，在LangChain中，每个`Agent`都应该在其提示模板中定义一个变量`{agent_scratchpad}`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee34599-40d1-4119-a8e5-63fb2a8e840a",
   "metadata": {},
   "source": [
    "### 3.3 AgentExecutor: Where Agents Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e704dc9-fc43-4e69-a41e-321cc17b6e6e",
   "metadata": {},
   "source": [
    "`AgentExecutor`是`Agent`（就像我们上面定义的那样）实际执行的地方。根据我们希望代理运行的方式，可以有不同类型的`AgentExecutor`。大多数情况下，我们希望使用LangChain提供的默认`AgentExecutor`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f2be4-e2de-444d-bf65-244954077f6e",
   "metadata": {},
   "source": [
    "以下代码片段来自`AgentExecutor`，展示了LangChain中通常如何执行`Agent`。\n",
    "```python\n",
    "class AgentExecutor(Chain):\n",
    "    ...\n",
    "    def _call(\n",
    "        self,\n",
    "        inputs: Dict[str, str],\n",
    "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Run text through and get agent response.\"\"\"\n",
    "        ...\n",
    "        # [1] To prevent `Agent`s from running into an infinite loop, `AgentExecutor` use\n",
    "        #     both number of LLM invocations (`iterations`) and used time (`time_elapsed`)\n",
    "        #     to stop execution even if `Agent` do not want to finish\n",
    "        iterations = 0\n",
    "        time_elapsed = 0.0\n",
    "        start_time = time.time()\n",
    "        # [2] We now enter into the agent loop (until it returns something).\n",
    "        while self._should_continue(iterations, time_elapsed):\n",
    "            # [3] Take a single step in the \"Thought/Action/Observation\" loop, \n",
    "            #     return either `AgentAction` plus input or `AgentFinish`\n",
    "            next_step_output = self._take_next_step(...)\n",
    "            if isinstance(next_step_output, AgentFinish):  # [4] Return if LLM decides to finish\n",
    "                return self._return(\n",
    "                    next_step_output, intermediate_steps, run_manager=run_manager\n",
    "                )\n",
    "    \n",
    "            intermediate_steps.extend(next_step_output)  # [5] Store current step, i.e, `AgentAction` plus input\n",
    "            if len(next_step_output) == 1:\n",
    "                next_step_action = next_step_output[0]\n",
    "                # See if tool should return directly\n",
    "                tool_return = self._get_tool_return(next_step_action)\n",
    "                if tool_return is not None:  # [6] Check the next `AgentAction` wants to return directly\n",
    "                    return self._return(\n",
    "                        tool_return, intermediate_steps, run_manager=run_manager\n",
    "                    )\n",
    "            iterations += 1\n",
    "            time_elapsed = time.time() - start_time\n",
    "        # [7] Deal with early stop, can still return something even if stopped in the middle\n",
    "        output = self.agent.return_stopped_response(\n",
    "            self.early_stopping_method, intermediate_steps, **inputs\n",
    "        )\n",
    "        return self._return(output, intermediate_steps, run_manager=run_manager)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603e894-a713-425e-8bd6-f05e3da36a55",
   "metadata": {},
   "source": [
    "### 3.4 Put It Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fb57e-c577-4954-a7c2-4bf07089347d",
   "metadata": {},
   "source": [
    "现在让我们将`Tool`、`Agent`和`AgentExecutor`结合起来，看看LangChain代理有哪些功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8990dd5d-478d-4ebf-87f5-0a4afcb2bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, AgentExecutor\n",
    "from langchain.agents.mrkl.base import ZeroShotAgent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.7)\n",
    "tools = load_tools(['llm-math', 'open-meteo-api'], llm=llm)\n",
    "\n",
    "agent = ZeroShotAgent.from_llm_and_tools(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print(executor.invoke('What is the weather in Berlin? Raise it to the power of 2.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce705842-df82-4862-abd2-7e44aabfc15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
